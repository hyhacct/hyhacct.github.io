[{"id":"2a7ed2ed5e24b574ac1497b2e3f1a5af","title":"使用Vue实现瀑布流布局","content":"概述瀑布流布局相比栅格网格不同的就是，只要卡片塞的合理，一般是不会出现空格。\n不像栅格，只能做水平对齐，但是如果卡片的高度不能统一，那就会出现很多空白的区域，影响美观。\n安装包vue 里面vue-masonry-wall就是用来做瀑布样式的，可以直接安装引入。\n\n\n\n\n\n\n\n\n\n安装之前先注意，如果你是vue2版本的话可能是要用npm install vue-masonry-wall这个。\n下面这个是vue3的安装，实际上我测试过在vue3里面直接执行pnpm install vue-masonry-wall，并且使用。\n会出现API 兼容性问题，导致出现错误，所以我猜测这两个应该是分为 vue3 和 vue2 两个版本使用的。\n123yarn add @yeger/vue-masonry-wallnpm install @yeger/vue-masonry-wall\n\n示例代码全局引入123456import &#123; createApp &#125; from &quot;vue&quot;;import MasonryWall from &quot;@yeger/vue-masonry-wall&quot;;const app = createApp();app.use(MasonryWall);\n\n组件内使用\n\n\n\n\n\n\n建议\n值得注意的是当数据量比较大时渲染压力会增加,建议做分页来缓解前端的渲染压力\n\n12345678910111213141516171819202122232425262728293031323334353637383940&lt;template&gt;  &lt;masonry-wall :items=&quot;items&quot; :column-width=&quot;300&quot; :gap=&quot;16&quot;&gt;    &lt;template #default=&quot;&#123; item &#125;&quot;&gt;      &lt;div class=&quot;item&quot;&gt;        &lt;img :src=&quot;item.image&quot; :alt=&quot;item.title&quot; /&gt;        &lt;h3&gt;&#123;&#123; item.title &#125;&#125;&lt;/h3&gt;        &lt;p&gt;&#123;&#123; item.description &#125;&#125;&lt;/p&gt;      &lt;/div&gt;    &lt;/template&gt;  &lt;/masonry-wall&gt;&lt;/template&gt;&lt;script setup&gt;import &#123; ref &#125; from &quot;vue&quot;;const items = ref([  &#123;    id: 1,    title: &quot;标题1&quot;,    description: &quot;描述1&quot;,    image: &quot;图片地址1&quot;,  &#125;,  // ... 更多数据]);&lt;/script&gt;&lt;style scoped&gt;.item &#123;  background: #fff;  border-radius: 8px;  padding: 16px;  box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);&#125;.item img &#123;  width: 100%;  height: auto;  border-radius: 4px;&#125;&lt;/style&gt;\n\n配置选项masonry-wall 组件支持以下主要配置：\n\nitems: 数组，必需，要显示的数据项\ncolumn-width: 数字，每列的宽度（像素）\ngap: 数字，列之间的间距（像素）\nrtl: 布尔值，是否从右到左布局\nssr-columns: 数字，服务器端渲染时的列数\n\n响应式处理为了在不同屏幕尺寸下获得最佳显示效果，可以使用计算属性动态设置列宽：\n12345678910&lt;script setup&gt;import &#123; computed &#125; from &quot;vue&quot;;const columnWidth = computed(() =&gt; &#123;  const screenWidth = window.innerWidth;  if (screenWidth &lt; 600) return 150;  if (screenWidth &lt; 900) return 200;  return 300;&#125;);&lt;/script&gt;\n","slug":"2025-07-18-13","date":"2025-07-18T15:06:23.000Z","categories_index":"Vue.js","tags_index":"Vue.js","author_index":"Reverse"},{"id":"e7e13627a554d1367d86ca0e77896cef","title":"Wails中Go结构或方法无法映射到前端","content":"概述最近发现一个奇怪的问题，我执行wails dev时突然发现我在app.go中暴露给前端的函数居然没能自动绑定到前端的wailsjs/go/apps/xxx下。\n经过一段时间排查发现是 go 语言导出函数的返回值带有复杂类型，就是time.Time这个类型导致的，原因很简单。\n执行命令尝试手动让他去绑定：\n1wails generate module\n\n然后出现了错误\n12345678╭─hyhacct@hyhacctdeMacBook-Air ~/workspace/PeachDRAC/PeachDRAC ‹main●›╰─$ wails generate module                                                                                                                  1 ↵2025/04/24 13:24:14 KnownStructs: model.TablePass       model.WailsCommunicateNot found: time.TimeKnownStructs: model.TablePass   model.WailsCommunicateNot found: time.Time ♥   If Wails is useful to you or your company, please consider sponsoring the project:\n\n这里就是在说 wails 其实并不支持time.Time这个类型，但是恰好我暴露的函数中，有一个返回值是结构体，结构体里面有个值类型就是time.Time。\n然后这个问题就顺其而然的产生了…\n解决办法直接在对应的结构体这个类型下，给他添加一个映射: ts_type:&quot;string&quot;\n意思就是告诉 Wails 将 time.Time 序列化为字符串，不将他作为一个特殊类型处理，其实就可以了。\n具体示例：(在对应的特殊类型后面添加ts_type映射)\n12345678910type TablePass struct &#123;\tID        int       `gorm:&quot;primary_key&quot; json:&quot;id&quot;`\tUsername  string    `gorm:&quot;not null&quot; json:&quot;username&quot;`\tPassword  string    `gorm:&quot;not null&quot; json:&quot;password&quot;`\tPort      string    `gorm:&quot;not null&quot; json:&quot;port&quot;`\tStatus    bool      `gorm:&quot;not null&quot; json:&quot;status&quot;`   // 是否启用\tPriority  int       `gorm:&quot;not null&quot; json:&quot;priority&quot;` // 优先级,数字越大越高\tCreatedAt time.Time `gorm:&quot;autoCreateTime&quot; json:&quot;created_at&quot; ts_type:&quot;string&quot;`\tUpdatedAt time.Time `gorm:&quot;autoUpdateTime&quot; json:&quot;updated_at&quot; ts_type:&quot;string&quot;`&#125;\n\n然后执行自动绑定，发现没有任何错误，OK，问题顺利解决。\n123456╭─hyhacct@hyhacctdeMacBook-Air ~/workspace/PeachDRAC/PeachDRAC ‹main●›╰─$ wails generate module ♥   If Wails is useful to you or your company, please consider sponsoring the project:https://github.com/sponsors/leaanthony╭─hyhacct@hyhacctdeMacBook-Air ~/workspace/PeachDRAC/PeachDRAC ‹main●›╰─$\n","slug":"2025-07-18-12","date":"2025-07-18T15:04:34.000Z","categories_index":"Go","tags_index":"Go Wails","author_index":"Reverse"},{"id":"87e97009ba513578bced279cc7705d0d","title":"强制更新Gorm零值","content":"概述在使用 Gorm 的Updates方法更新字段时，一般情况下他会忽略掉零值，例如 false、0、&quot;&quot;，这些都属于零值\n如果你有个字段叫status，类型为bool表示该记录的状态，那么当你想修改他为false时是不会成功的。\n解决方法\n\n\n\n\n\n\n注意\n小心使用哦,别改崩了\n\nGORM 默认忽略零值（如 false），直接通过Select方法指定强制更新字段，即便你这个字段将被修改为零值。\n1234func (TablePass) AddOrUpdate(config TablePass) error &#123;    return farmework.ModuleOrm.Where(&quot;id = ?&quot;, config.ID).        Assign(config).Select(&quot;status&quot;).FirstOrCreate(&amp;config).Error&#125;\n","slug":"2025-07-18-11","date":"2025-07-18T14:59:24.000Z","categories_index":"Go","tags_index":"Go Gorm","author_index":"Reverse"},{"id":"f51d2d839d5d520af441020c6868a0d3","title":"Vue脚手架模板","content":"\n\n\n\n\n\n有啥用?\n浅浅记录一下在使用 Vue 的轮子时,各个支持库的模板,方便在新起项目时可以快速 CV 上去 :)\n\nRouter Template\n\n\n\n\n\n\n\n\n这是路由组件的 ts 代码模板,可以直接 CV 到/src/router/index.ts使用,删除一些自己不需要的东西就行.\n\n点我查看代码\n1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465import &#123; createRouter, createWebHashHistory, RouteRecordRaw &#125; from &quot;vue-router&quot;;import &#123; useUserStore &#125; from &quot;@/stores/user&quot;; // 若使用 Piniaimport &#123; ElMessage &#125; from &quot;element-plus&quot;; // 可换成任意 UI 库import NProgress from &quot;nprogress&quot;; // 替代 loadingBar// 页面组件引入import ViewLogin from &quot;@/views/Login.vue&quot;;import ViewHome from &quot;@/views/Home.vue&quot;;import View404 from &quot;@/views/404.vue&quot;;// 路由配置const routes: RouteRecordRaw[] = [  &#123;    path: &quot;/&quot;,    redirect: &quot;/home&quot;,  &#125;,  &#123;    path: &quot;/login&quot;,    name: &quot;Login&quot;,    component: ViewLogin,    meta: &#123; public: true &#125;,  &#125;,  &#123;    path: &quot;/home&quot;,    name: &quot;Home&quot;,    component: ViewHome,    meta: &#123; requiresAuth: true &#125;,  &#125;,  &#123;    path: &quot;/:pathMatch(.*)*&quot;,    name: &quot;NotFound&quot;,    component: View404,    meta: &#123; public: true &#125;,  &#125;,];const router = createRouter(&#123;  history: createWebHashHistory(),  routes,&#125;);// 路由守卫router.beforeEach((to, from, next) =&gt; &#123;  NProgress.start();  const userStore = useUserStore();  const isAuthenticated = !!userStore.token;  if (to.meta.requiresAuth &amp;&amp; !isAuthenticated) &#123;    ElMessage.warning(&quot;请先登录&quot;);    return next(&#123; name: &quot;Login&quot; &#125;);  &#125;  if (to.path === &quot;/login&quot; &amp;&amp; isAuthenticated) &#123;    return next(&#123; name: &quot;Home&quot; &#125;);  &#125;  next();&#125;);router.afterEach(() =&gt; &#123;  NProgress.done();&#125;);export default router;\n\n\n\nPinia [TypeScript] Template\n\n\n\n\n\n\n\n\n这是 pinia 状态管理插件的 TS 模板,一般是放在/src/stores/xxxx.ts的\n\n点我查看代码\n123456789101112131415161718192021222324252627282930313233343536373839404142434445import &#123; defineStore &#125; from &quot;pinia&quot;;interface UserInfo &#123;  id: string;  name: string;  email?: string;  [key: string]: any;&#125;export const useUserStore = defineStore(&quot;user&quot;, &#123;  state: (): &#123;    token: string;    userInfo: UserInfo | null;  &#125; =&gt; (&#123;    token: &quot;&quot;,    userInfo: null,  &#125;),  getters: &#123;    isLogin: (state) =&gt; !!state.token,    username: (state) =&gt; state.userInfo?.name || &quot;&quot;,  &#125;,  actions: &#123;    setToken(token: string) &#123;      this.token = token;    &#125;,    setUserInfo(info: UserInfo) &#123;      this.userInfo = info;    &#125;,    logout() &#123;      this.token = &quot;&quot;;      this.userInfo = null;    &#125;,  &#125;,  // 持久化（可选，需要配合 pinia-plugin-persistedstate 插件）  persist: &#123;    key: &quot;user-store&quot;,    paths: [&quot;token&quot;, &quot;userInfo&quot;],    storage: sessionStorage,  &#125;,&#125;);\n\n\n\nPinia [JavaScript] Template\n\n\n\n\n\n\n\n\n这是 pinia 状态管理插件的 JS 模板,一般是放在/src/stores/xxxx.js的\n\n点我查看代码\n1234567891011121314151617181920212223242526272829303132333435import &#123; defineStore &#125; from &quot;pinia&quot;;export const useUserStore = defineStore(&quot;user&quot;, &#123;  state: () =&gt; (&#123;    token: &quot;&quot;,    userInfo: null,  &#125;),  getters: &#123;    isLogin: (state) =&gt; !!state.token,    username: (state) =&gt; state.userInfo?.name || &quot;&quot;,  &#125;,  actions: &#123;    setToken(token) &#123;      this.token = token;    &#125;,    setUserInfo(info) &#123;      this.userInfo = info;    &#125;,    logout() &#123;      this.token = &quot;&quot;;      this.userInfo = null;    &#125;,  &#125;,  // 开启持久化（需要 pinia-plugin-persistedstate 插件）  persist: &#123;    key: &quot;user-store&quot;,    paths: [&quot;token&quot;, &quot;userInfo&quot;],    storage: sessionStorage,  &#125;,&#125;);\n\n\n\naxios 二次封装\n\n\n\n\n\n\n\n\n可以直接写到/src/api/request.ts\n\n点我查看代码\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566import axios, &#123; AxiosInstance, AxiosRequestConfig, AxiosResponse &#125; from &quot;axios&quot;;import &#123; ElMessage &#125; from &quot;element-plus&quot;;import &#123; useUserStore &#125; from &quot;@/stores/user&quot;;const BASE_URL = import.meta.env.VITE_API_BASE_URL || &quot;/api&quot;;const service: AxiosInstance = axios.create(&#123;  baseURL: BASE_URL,  timeout: 10000,  headers: &#123;    &quot;Content-Type&quot;: &quot;application/json&quot;,  &#125;,&#125;);// 请求拦截器service.interceptors.request.use(  (config: AxiosRequestConfig) =&gt; &#123;    const userStore = useUserStore();    const token = userStore.token;    if (token) &#123;      config.headers = &#123;        ...config.headers,        Authorization: `Bearer $&#123;token&#125;`,      &#125;;    &#125;    return config;  &#125;,  (error) =&gt; &#123;    return Promise.reject(error);  &#125;);// 响应拦截器service.interceptors.response.use(  (response: AxiosResponse) =&gt; &#123;    const &#123; data &#125; = response;    // 根据业务约定处理    if (data.code !== 0) &#123;      ElMessage.error(data.message || &quot;请求失败&quot;);      return Promise.reject(data);    &#125;    return data.data; // 默认返回 data 下的 data  &#125;,  (error) =&gt; &#123;    const status = error?.response?.status;    if (status === 401) &#123;      const userStore = useUserStore();      userStore.logout();      ElMessage.error(&quot;登录已过期，请重新登录&quot;);      // 可跳转登录页    &#125; else if (status === 500) &#123;      ElMessage.error(&quot;服务器错误&quot;);    &#125; else &#123;      ElMessage.error(error?.response?.data?.message || &quot;请求异常&quot;);    &#125;    return Promise.reject(error);  &#125;);export default service;\n\n\n\n\n\n\n\n\n\n\n怎么使用? 参考下面的代码\n123456789101112131415161718import request from &quot;@/api/request&quot;;interface LoginParams &#123;  username: string;  password: string;&#125;interface LoginResponse &#123;  token: string;  userInfo: &#123;    id: string;    name: string;  &#125;;&#125;export function login(data: LoginParams) &#123;  return request.post&lt;LoginResponse&gt;(&quot;/auth/login&quot;, data);&#125;\n\n\n\n","slug":"2025-07-18-10","date":"2025-07-18T14:40:25.000Z","categories_index":"Vue.js","tags_index":"Vue.js","author_index":"Reverse"},{"id":"412695f5eb189a644d181b95b6e4062a","title":"在Linux下创建Supervisord服务单元","content":"概述Supervisord 是一个轻量级的进程管理工具。它允许创建和管理多个进程，并提供一些高级功能，如进程监控、自动重启、日志管理等。\n他和 Systemd 一样，都是用于管理进程的工具。\n安装1apt install supervisor\n\n安装完成后有个配置文件: supervisord.conf 如果找不到的话用 find 寻找一下就行.\n然后需要启动 supervisord 服务:\n1supervisord -c /etc/supervisor/supervisord.conf\n\n\n\n\n\n\n\n\n\n\n注意下,这里的配置文件是你实际的配置文件所在路径,如果你移动过这个 conf 文件的位置,请使用实际的路径.\n进行配置和上一篇文章一样继续假设我们的应用叫 project-apps 并且需要创建一个服务单元.\n给supervisord 添加配置:\n1234567891011121314151617[supervisord]nodaemon=truelogfile=/dev/nulllogfile_maxbytes=0pidfile=/tmp/supervisord.pid[program:project-apps]command=/usr/local/bin/project-appsuser=nobodyenvironment=PATH=&quot;/usr/local/bin:/usr/bin:/bin&quot;autostart=trueautorestart=truestartsecs=10startretries=3redirect_stderr=truestdout_logfile=/dev/stdoutstderr_logfile=/dev/stderr\n\n逐项解释：\n[supervisord] 部分：\n\nnodaemon=true：以非守护进程模式运行（容器需要前台进程）。\nlogfile=/dev/null：禁用 supervisord 自身的日志文件（容器日志通过 stdout&#x2F;stderr 收集）。\nlogfile_maxbytes=0：防止日志文件增长。\npidfile=/tmp/supervisord.pid：指定 PID 文件路径。\n\n[program:project-apps] 部分：\n\ncommand=/usr/local/bin/project-apps：运行的命令，等价于 systemd 的 ExecStart。\nuser=nobody：以 nobody 用户运行，等价于 systemd 的 User&#x3D;nobody。\nenvironment=PATH=...：设置环境变量，等价于 systemd 的 Environment。\nautostart=true：supervisord 启动时自动启动 project-apps\nautorestart=true：进程退出时自动重启，等价于 systemd 的 Restart&#x3D;always。\nstartsecs=10：进程运行 10 秒后认为启动成功（避免频繁重启）。\nstartretries=3：启动失败时重试 3 次。\nredirect_stderr=true：将 stderr 重定向到 stdout。\nstdout_logfile=/dev/stdout：将 stdout 输出到容器日志。\nstderr_logfile=/dev/stderr：将 stderr 输出到容器日志。\n\n启动1supervisord -c /etc/supervisor/supervisord.conf\n\n查看状态1supervisorctl status\n\n停止1supervisorctl stop project-apps\n\n重启1supervisorctl restart project-apps\n\n支持的各个参数\n\n\n参数名\n描述\n类型\n默认值\n示例值\n与 systemd 的对应\n\n\n\ncommand\n指定要运行的命令或可执行文件路径\n字符串\n无（必填）\nproject-apps\nExecStart\n\n\nuser\n指定运行进程的用户\n字符串\n无（以 supervisord 的用户运行）\nnobody\nUser\n\n\nenvironment\n设置进程的环境变量，格式为 KEY&#x3D;”value”,KEY2&#x3D;”value2”\n字符串\n无\nPATH=&quot;/usr/local/bin:/usr/bin:/bin&quot;\nEnvironment\n\n\ndirectory\n运行命令前切换的工作目录\n字符串\n无（当前目录）\n/app\nWorkingDirectory\n\n\nautostart\n是否在 supervisord 启动时自动启动进程\n布尔值\ntrue\ntrue\nWantedBy（间接对应）\n\n\nautorestart\n进程退出时是否自动重启（true&#x2F;false&#x2F;unexpected）\n字符串\nfalse\ntrue\nRestart（always 对应 true）\n\n\nstartsecs\n进程运行多少秒后认为启动成功（用于重启判断）\n整数\n1\n10\n无直接对应（类似 RestartSec）\n\n\nstartretries\n启动失败时的最大重试次数\n整数\n3\n3\n无直接对应\n\n\nexitcodes\n视为正常退出的退出码（仅当 autorestart&#x3D;unexpected 时生效）\n逗号分隔的整数\n0\n0,2\n无直接对应\n\n\nstopwaitsecs\n停止进程时等待的秒数（超时后发送 SIGKILL）\n整数\n10\n10\nTimeoutStopSec\n\n\nstopasgroup\n是否向整个进程组发送停止信号\n布尔值\nfalse\ntrue\n无直接对应（类似 KillMode&#x3D;process-group）\n\n\nkillasgroup\n是否向整个进程组发送终止信号（SIGKILL）\n布尔值\nfalse\ntrue\n无直接对应\n\n\nstopsignal\n用于停止进程的信号\n字符串\nTERM\nINT\nKillSignal\n\n\npriority\n进程启动的优先级（数字越小优先级越高）\n整数\n999\n100\n无直接对应（类似 Nice 或启动顺序）\n\n\nnumprocs\n启动的进程实例数（多实例运行）\n整数\n1\n2\n无直接对应\n\n\nnumprocs_start\n多实例进程的起始编号（与 numprocs 配合）\n整数\n0\n1\n无直接对应\n\n\nprocess_name\n进程名称模板（用于多实例，含 % 占位符）\n字符串\n%(program_name)s\n%(program_name)s_%(process_num)02d\n无直接对应\n\n\nredirect_stderr\n是否将 stderr 重定向到 stdout\n布尔值\nfalse\ntrue\n无直接对应（日志处理相关）\n\n\nstdout_logfile\nstdout 日志输出文件路径（支持 &#x2F;dev&#x2F;stdout）\n字符串\nAUTO（自动生成日志文件）\n/dev/stdout\n无直接对应（systemd 使用 journalctl）\n\n\nstdout_logfile_maxbytes\nstdout 日志文件的最大大小\n字符串\n50MB\n10MB\n无直接对应\n\n\nstdout_logfile_backups\nstdout 日志文件的备份数量\n整数\n10\n5\n无直接对应\n\n\nstderr_logfile\nstderr 日志输出文件路径\n字符串\nAUTO\n/dev/stderr\n无直接对应\n\n\nstderr_logfile_maxbytes\nstderr 日志文件的最大大小\n字符串\n50MB\n10MB\n无直接对应\n\n\nstderr_logfile_backups\nstderr 日志文件的备份数量\n整数\n10\n5\n无直接对应\n\n\nstdout_capture_maxbytes\nstdout 捕获缓冲区大小（用于事件监听）\n字符串\n0\n1MB\n无直接对应\n\n\nstdout_events_enabled\n是否启用 stdout 事件（用于事件监听）\n布尔值\nfalse\ntrue\n无直接对应\n\n\nstderr_events_enabled\n是否启用 stderr 事件\n布尔值\nfalse\ntrue\n无直接对应\n\n\n","slug":"2025-07-18-08","date":"2025-07-18T14:16:37.000Z","categories_index":"运维","tags_index":"服务单元 Linux","author_index":"Reverse"},{"id":"cb4e47217e236130c02e8a1c94b69087","title":"在Linux下创建System服务单元","content":"概述Systemd 是 Linux 系统的一种初始化系统（init），主要负责控制系统的启动和运行，并提供了一种基于服务的管理机制。它取代了传统的 init 系统，成为现代 Linux 发行版的标准。\n这里假设我需要为我的应用创建一个名字叫project-apps.service的服务单元。\n创建服务单元12345678910111213141516171819cat &gt;/etc/systemd/system/project-apps.service &lt;&lt;EOF[Unit]Description=project-apps ServiceAfter=network.target[Service]ExecStart=/usr/local/bin/project-appsRestart=alwaysUser=nobodyGroup=nogroupEnvironment=PATH=/usr/local/bin:/usr/bin:/bin[Install]WantedBy=multi-user.targetEOFsystemctl daemon-reloadsystemctl enable project-apps.servicesystemctl restart project-apps.service\n\n\ncat &gt;: 使用 cat 命令将后续内容写入文件。\n/etc/systemd/system/project-apps.service: 指定文件路径，systemd 服务单元文件通常存放在 &#x2F;etc&#x2F;systemd&#x2F;system&#x2F; 目录下。\n&lt;&lt;EOF ... EOF: 使用 heredoc 语法，将多行内容写入文件，直到遇到 EOF 标记。\n\n[Unit] 部分123[Unit]Description=project-apps ServiceAfter=network.target\n\n\nDescription: 服务描述，显示为 Dcim Service，用于标识服务的用途。\nAfter=network.target: 指定服务在 network.target（网络服务）启动后再启动，确保网络可用。\n\n[Service] 部分123456[Service]ExecStart=/usr/local/bin/project-appsRestart=alwaysUser=nobodyGroup=nogroupEnvironment=PATH=/usr/local/bin:/usr/bin:/bin\n\n\nExecStart: 指定服务启动时执行的命令 &#x2F;usr&#x2F;local&#x2F;bin&#x2F;project-apps。这意味着有一个可执行文件 project-apps 位于 &#x2F;usr&#x2F;local&#x2F;bin&#x2F;。\nRestart=always: 如果服务因任何原因停止（例如崩溃），systemd 将自动重启服务。\nUser=nobody: 服务以 nobody 用户身份运行，这是一个低权限用户，用于提高安全性。\nGroup=nogroup: 服务以 nogroup 组身份运行，同样是为了限制权限。\nEnvironment: 设置环境变量 PATH，确保服务可以找到 &#x2F;usr&#x2F;local&#x2F;bin、&#x2F;usr&#x2F;bin 和 &#x2F;bin 目录中的可执行文件。\n\n[Install] 部分12[Install]WantedBy=multi-user.target\n\n\nWantedBy=multi-user.target: 指定服务在 multi-user.target（多用户模式，相当于系统启动到命令行环境）时启用。这是典型的非图形化服务的目标。\n\n后续操作1systemctl daemon-reload\n\n\nsystemctl daemon-reload: 通知 systemd 重新加载配置文件。因为我们刚刚创建或修改了 dcim.service 文件，此命令确保 systemd 识别新的服务定义。\n需要 sudo 权限，因为修改 systemd 配置是系统级操作。\n\n12systemctl enable project-apps.servicesystemctl restart project-apps.service\n\n\nsystemctl enable project-apps.service: 启用服务，使其在系统启动时自动启动。\nsystemctl restart project-apps.service: 重新启动服务，确保配置生效。\n\n另外，如果需要查看服务状态，可以使用以下命令：\n1systemctl status project-apps.service\n\n希望查看服务日志，可以使用以下命令：\n1journalctl -u project-apps.service\n","slug":"2025-07-18-09","date":"2025-07-18T14:16:37.000Z","categories_index":"运维","tags_index":"服务单元 Linux","author_index":"Reverse"},{"id":"5cd89c20fd6a2aad9144cf965a99cbdc","title":"利用zabbix api计算流量月95值","content":"直接提供脚本虽然这个脚本是让 AI 帮忙写的,但经过实际验证,是有效的,并且我一直在使用\n\n\n\n\n\n\n\n\n\n注意这的 1,2,3 步骤中的一些参数需要自己配置,比如时间范围,单位换算,文件路径等.\n根据你实际情况改改,另外就是一些必备软件包得装一下,比如jq bc curl什么的.\n最重要的是ITEM_ID这个变量,你需要从 zabbix 中找到你想计算 95 的流量图,然后把他的 itemid 拿出来.\n12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394#!/usr/bin/env bash# 1. Zabbix API 参数配置ZABBIX_URL=&quot;https://xxxxxxx/api_jsonrpc.php&quot; # 你的 zabbix API 地址ITEM_ID=&quot; 123456&quot; # 你的 item id,这个是流量图的 itemid,可以自己找一下AUTH_TOKEN=&quot;xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx&quot; # 你的 auth token# 2. 时间范围,假设（2025-04-01 ~ 2025-04-30）TIME_FROM=1743436800 # 2025-04-01 00:00:00 转换到对应的秒级时间戳TIME_TILL=1746028799 # 2025-04-30 23:59:59 转换到对应的秒级时间戳# 3. 单位换算：字节 =&gt; MBBYTES_TO_MB=1048576JSON_PATH=&quot;/tmp/zabbix.json&quot; # zbx 请求数据CSV_PATH=&quot;/tmp/zabbix_full_data.csv&quot; # 全量数据(每 5 分钟一个点的 95 值)ROW_PATH=&quot;/tmp/zabbix_row_data.csv&quot; # 每分钟数据# 4. 获取历史数据（只下载一次）if [ ! -f &quot;$JSON_PATH&quot; ]; then  echo &quot;拉取 Zabbix 数据中...&quot;  RESPONSE=$(curl -s &quot;$ZABBIX_URL&quot; \\    -H &quot;Content-Type: application/json&quot; \\    --data-raw &quot;&#123;    \\&quot;jsonrpc\\&quot;: \\&quot;2.0\\&quot;,    \\&quot;id\\&quot;: 1,    \\&quot;method\\&quot;: \\&quot;history.get\\&quot;,    \\&quot;params\\&quot;: &#123;      \\&quot;output\\&quot;: \\&quot;extend\\&quot;,      \\&quot;itemids\\&quot;: \\&quot;$ITEM_ID\\&quot;,      \\&quot;history\\&quot;: 3,      \\&quot;time_from\\&quot;: $TIME_FROM,      \\&quot;time_till\\&quot;: $TIME_TILL,      \\&quot;sortfield\\&quot;: [\\&quot;clock\\&quot;, \\&quot;itemid\\&quot;],      \\&quot;sortorder\\&quot;: \\&quot;ASC\\&quot;    &#125;,    \\&quot;auth\\&quot;: \\&quot;$AUTH_TOKEN\\&quot;  &#125;&quot;)  echo &quot;$RESPONSE&quot; &gt;&quot;$JSON_PATH&quot;else  RESPONSE=$(awk &#x27;NF&#x27; &quot;$JSON_PATH&quot;)fi# 5. 提取时间和流量，转换为 MB，并写入 CSV 文件echo &quot;Timestamp,Datetime,Value(MB)&quot; &gt;&quot;$CSV_PATH&quot;# 暂存 5 分钟分组后的最大值declare -A GROUPED_MAX# 从 JSON 中提取数据并分组while IFS= read -r line; do  CLOCK=$(echo &quot;$line&quot; | jq -r &#x27;.clock&#x27;)  VALUE=$(echo &quot;$line&quot; | jq -r &#x27;.value&#x27;)  VALUE_MB=$(awk -v val=&quot;$VALUE&quot; -v factor=&quot;$BYTES_TO_MB&quot; &#x27;BEGIN &#123;printf &quot;%.2f&quot;, val / factor&#125;&#x27;)  # 向下取整到 5 分钟（300 秒）粒度  GROUP_TS=$((CLOCK / 300 * 300))  # 如果该组未存在，或当前值更大，更新最大值  if [[ -z &quot;$&#123;GROUPED_MAX[$GROUP_TS]&#125;&quot; ]] || (($(echo &quot;$VALUE_MB &gt; $&#123;GROUPED_MAX[$GROUP_TS]&#125;&quot; | bc -l))); then    GROUPED_MAX[$GROUP_TS]=$VALUE_MB  fi  # 写出每分钟的数据,带可读时间  DATETIME=$(date -d &quot;@$CLOCK&quot; &quot;+%Y-%m-%d %H:%M:%S&quot;)  echo &quot;$DATETIME,$VALUE_MB&quot; &gt;&gt;&quot;$ROW_PATH&quot;done &lt; &lt;(echo &quot;$RESPONSE&quot; | jq -c &#x27;.result | sort_by(.clock)[]&#x27;)# 提取排序后的 5 分钟粒度时间点和值，写入 CSV，并保存值用于 P95VALUES_MB=()for ts in $(printf &quot;%s\\n&quot; &quot;$&#123;!GROUPED_MAX[@]&#125;&quot; | sort -n); do  val=&quot;$&#123;GROUPED_MAX[$ts]&#125;&quot;  datetime=$(date -d &quot;@$ts&quot; &quot;+%Y-%m-%d %H:%M:%S&quot;)  echo &quot;$ts,$datetime,$val&quot; &gt;&gt;&quot;$CSV_PATH&quot;  VALUES_MB+=(&quot;$val&quot;)done# 6. 统计与 P95 计算TOTAL=$&#123;#VALUES_MB[@]&#125;if [[ $TOTAL -lt 1 ]]; then  echo &quot;未获取到有效数据，退出。&quot;  exit 1fiSORTED=($(printf &quot;%s\\n&quot; &quot;$&#123;VALUES_MB[@]&#125;&quot; | sort -n))PERCENTILE_INDEX=$(echo &quot;$TOTAL * 0.95&quot; | bc | awk &#x27;&#123;printf(&quot;%d&quot;, ($1==int($1))?$1:$1+1)&#125;&#x27;)P95_VALUE=$&#123;SORTED[$((PERCENTILE_INDEX - 1))]&#125;# 7. 输出汇总echo &quot;✅ 数据点总数: $TOTAL&quot;echo &quot;📈 95 百分位位置: $PERCENTILE_INDEX&quot;echo &quot;📊 整体 95 值: $P95_VALUE MB&quot;echo &quot;📁 CSV 文件已生成: $CSV_PATH&quot;\n\n最终结果大概长这样:\n1234567✅ 数据点总数: 3589📈 95 百分位位置: 3410📊 整体 95 值: 1955.15 MB📁 CSV 文件已生成: /tmp/zabbix_full_data.csv\n","slug":"2025-07-18-07","date":"2025-07-18T14:12:49.000Z","categories_index":"运维","tags_index":"zabbix 月95","author_index":"Reverse"},{"id":"c59c56761bc7b0b0394e25c388e5d7f6","title":"利用nftables做端口流量统计","content":"概述通过nftables规则对特定端口范围做计数流量统计,可以借此计算瞬时流量.\n写规则假设这里我统计的是11000-19000端口范围的流量,入站和出站都统计,然后用计数器来计算流量.\n大概流程就是创一个名字叫portstats的表,然后创两个链,一个叫input_chain,一个叫output_chain,\n然后创两个计数器,一个叫input_tcp_range,一个叫output_tcp_range,然后创两个规则,一个叫input_tcp_range,一个叫output_tcp_range.\n12345678910111213141516171819202122232425262728293031# 创建表和链nft add table inet portstatsnft add chain inet portstats input_chain &#123; type filter hook input priority 0\\; &#125;nft add chain inet portstats output_chain &#123; type filter hook output priority 0\\; &#125;# 创建表nft add table inet portstats# 创建 input 链（接收进入本机的数据）nft add chain inet portstats input_chain &#123; type filter hook input priority 0\\; &#125;# 创建 output 链（从本机发出的数据）nft add chain inet portstats output_chain &#123; type filter hook output priority 0\\; &#125;# 创建计数器 TCPnft add counter inet portstats input_tcp_rangenft add counter inet portstats output_tcp_range# 创建计数器 UDPnft add counter inet portstats input_udp_rangenft add counter inet portstats output_udp_range# 入站 TCPnft add rule inet portstats input_chain tcp dport 11000-19000 counter name input_tcp_range# 入站 UDPnft add rule inet portstats input_chain udp dport 11000-19000 counter name input_udp_range# 出站 TCPnft add rule inet portstats output_chain tcp sport 11000-19000 counter name output_tcp_range# 出站 UDPnft add rule inet portstats output_chain udp sport 11000-19000 counter name output_udp_range\n\n创建完成后,可以查看这个表,能直接看到他的流量统计.\n在输出中,能看到counter的流量统计,packets是包的数量,bytes是字节数.\n\ninput_tcp_range 入站 TCP 流量统计\noutput_tcp_range 出站 TCP 流量统计\ninput_udp_range 入站 UDP 流量统计\noutput_udp_range 出站 UDP 流量统计\n\n\n\n\n\n\n\n\n\n\n当然,你可以直接通过他的 bytes 来计算计数流量,包括瞬时流量你也能记录到.\n1nft list table inet portstats\n\n1234567891011121314151617181920212223242526272829303132333435root@localhost:~# nft list table inet portstatstable inet portstats &#123;        counter input_tcp_range &#123;                packets 3646743 bytes 234844099        &#125;        counter output_tcp_range &#123;                packets 2718337 bytes 7699060368        &#125;        counter input_udp_range &#123;                packets 83 bytes 12353        &#125;        counter output_udp_range &#123;                packets 96 bytes 7375        &#125;        chain input_chain &#123;                type filter hook input priority filter; policy accept;                tcp dport 11000-19000 counter name &quot;input_tcp_range&quot;                udp dport 11000-19000 counter name &quot;input_udp_range&quot;                tcp dport 11000-19000 counter name &quot;input_tcp_range&quot;                udp dport 11000-19000 counter name &quot;input_udp_range&quot;        &#125;        chain output_chain &#123;                type filter hook output priority filter; policy accept;                tcp sport 11000-19000 counter name &quot;output_tcp_range&quot;                udp sport 11000-19000 counter name &quot;output_udp_range&quot;                tcp sport 11000-19000 counter name &quot;output_tcp_range&quot;                udp sport 11000-19000 counter name &quot;output_udp_range&quot;        &#125;&#125;root@localhost:~#\n\n流量计算比如上面的output_tcp_range当前流量在7699060368字节,如果要转换到 Mb 单位,你应该:\n1echo &#x27;scale=2; 7699060368 / 1048576&#x27; | bc\n\n单位是 Mb,这样计算出来的结果仅仅只是计数器记录的流量,并不是瞬时流量.\n17342.39\n\n计算瞬时流量原理也很简单,先获取当前计数器记录的流量,然后 sleep10 秒后,再获取一次计数器记录的流量,然后计算两次的差值.\n123nft list table inet portstatssleep 10 # 等待 10 秒再取一次nft list table inet portstats\n\n比如我这里两次执行结果的input_tcp_range.\n\n第一次 234844099\n第二次 4346338221\n那么瞬时流量计算方式直接参考以下脚本\n\n\n\n\n\n\n\n\n\n\n第二次的结果减去第一次的结果,并且除以 10 的延迟秒,得到瞬时流量(如果要到 Mb 单位则再除以 1048576).\n如果你的延迟设置的不是 10 秒,而是 60 秒,那你就得除以 60.\n1echo &#x27;scale=2; (4346338221 - 234844099) / 1048576 / 10&#x27; | bc # 单位是 Mb/s\n\n1392.10\n\n删除规则如果后续你不想要这个表或者这些规则了,可以直接删除这张表,他会将这个表下的规则,链,计数器一并清理.\n1nft delete table inet portstats\n","slug":"2025-07-18-06","date":"2025-07-18T14:10:07.000Z","categories_index":"运维","tags_index":"nftables","author_index":"Reverse"},{"id":"5861fe1ef331a2f0173b8f2c74ba7f6a","title":"为服务器启用超线程模式","content":"查看是否启用超线程如果 Thread(s) per core: 2，说明超线程已启用（每个物理核心有 2 个逻辑线程）。\n如果 Thread(s) per core: 1，说明超线程未启用。\n1lscpu | grep &quot;Thread(s) per core&quot;\n\n启用所有核心大概这样,写入 1 表示启用此核心,确保核心全部启用\n1234for CPU in /sys/devices/system/cpu/cpu[0-9]*; do  sudo bash -c &quot;echo 1 &gt; $CPU/online&quot; 2&gt;/dev/nulldonelscpu | grep &quot;Thread(s) per core&quot;\n\n启用超线程这里以 PowerEdge R730 机型为例,重启按 F2 进入 BIOS.\n然后按照下面的图片找到对应的选项并且将其启用即可\n\n进入 System BIOS 选项\n选择 Precessor Settings 选项(处理器设置)\n将 Logical Processor 设置为 Enable(启用即可)\n\n\n\n\n\n\n\n\n\n\nLogical Processor 的名字其实不一定,有时也叫 Hyper-Threading 或 Logical Processor Enable 看是什么机型\n\n\n\n验证结果保存 BIOS 配置并且退出,然后重启进入系统,再次尝试查看\n输出结果中的Thread(s) per core为 2 表示就启用了超线程\n1lscpu | grep &quot;Thread(s) per core&quot;\n\n或者\n1lscpu\n","slug":"2025-07-18-05","date":"2025-07-18T14:06:43.000Z","categories_index":"运维","tags_index":"超线程","author_index":"Reverse"},{"id":"b72299e78af8a95e50e0ce74a5a78e6d","title":"NaiveUI的Table表分页配置","content":"因为 NaiveUI 的 DataTable 数据表格组件支持 pagination 参数,所以我一直固定使用这个模板来作为分配配置,而不需要后端来分页\n\n\n\n\n\n\nTIP\n参考代码,在代码中,你无需关注他是怎么实现的,只需要定义好pagination对象,并且配置到数据表格组件中的 pagination 参数即可\n\n1234567891011121314151617181920212223242526272829303132333435&lt;template&gt;  &lt;n-data-table :pagination=&quot;pagination&quot; /&gt;&lt;/template&gt;&lt;script setup&gt;const pagination = &#123;  prefix(&#123; itemCount &#125;) &#123;    return `总计 $&#123;itemCount&#125; 条数据`;  &#125;,  pageSizes: [    &#123;      label: &quot;默认10条&quot;,      value: 10,    &#125;,    &#123;      label: &quot;全部显示&quot;,      value: 9999,    &#125;,    &#123;      label: &quot;20 每页&quot;,      value: 20,    &#125;,    &#123;      label: &quot;30 每页&quot;,      value: 30,    &#125;,    &#123;      label: &quot;40 每页&quot;,      value: 40,    &#125;,  ],  showSizePicker: true,  displayOrder: [&quot;quick-jumper&quot;, &quot;pages&quot;, &quot;size-picker&quot;],&#125;;&lt;/script&gt;\n","slug":"2025-07-18-03","date":"2025-07-18T13:59:31.000Z","categories_index":"Vue.js","tags_index":"Vue.js NaiveUI","author_index":"Reverse"},{"id":"1c2170fb6fef60f29c3c2770dcf97c19","title":"使用Go从Chroom中获取页面Cookies","content":"概述浅浅的玩一下github.com/go-rod/rod这个库.\n通过这个支持库,可以很方便的打开一个浏览器并且让他访问一个 url,在他访问 url 时你还可以监听这个 url 的 cookies.\n开始实操为了防止被检测到自动化，我这里是注入了 js 屏蔽了检测。\n\n首先使用browser.MustPage(&quot;&quot;)打开了一个空的标签页。\n注入 JS 脚本修改navigator.webdriver为false。\n注入修改完成后再打开真实的目标 URL，这样目标网站就没法通过这个值去检测我是不是自动化程序了。\n同时滑块成功后页面会自动跳转到其他地方，所以我做了一个拦截，如果不需要的话可以直接删除。\n\n\n\n\n\n\n\n\n\n\n可能要注意下，不一定所有的站点都是通过webdriver来检测自动化程序的，但是我这里只提供这个方式，至于其他的需要按照实际场景来看。\n并且我这里 go 程序只是为了获取滑块后的 cookies，如果想获取请求头或者其他东西的话，可能得自己再研究下。\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778package mainimport (\t&quot;context&quot;\t&quot;log/slog&quot;\t&quot;time&quot;\t&quot;github.com/go-rod/rod&quot;\t&quot;github.com/go-rod/rod/lib/launcher&quot;\t&quot;github.com/go-rod/rod/lib/proto&quot;)func main() &#123;  url := &quot;https://qq.com&quot;\tu := launcher.New().\t\tHeadless(false). // 显示窗口\t\t// 设置窗口尺寸（可选）\t\tSet(&quot;window-size&quot;, &quot;1200,800&quot;).\t\tSet(&quot;disable-blink-features&quot;, &quot;AutomationControlled&quot;).\t\tMustLaunch()\tbrowser := rod.New().ControlURL(u).MustConnect()\t// 打开页面\tpage := browser.MustPage(&quot;&quot;)\t// 在页面加载前注入 JavaScript，修改 navigator.webdriver\t_, err := page.EvalOnNewDocument(`\t\tObject.defineProperty(navigator, &#x27;webdriver&#x27;, &#123;\t\t\tget: () =&gt; false\t\t&#125;);\t`)\tif err != nil &#123;\t\tslog.Error(&quot;在页面加载前注入 JavaScript，修改 navigator.webdriver失败&quot;, &quot;ProxyService&quot;, err)\t&#125;\t// 访问目标页面\tpage.MustNavigate(url).MustWaitLoad()\t// 拦截导航请求，禁止跳转\trouter := page.HijackRequests()\trouter.MustAdd(&quot;*&quot;, func(ctx *rod.Hijack) &#123;\t\t// 如果请求是导航（即页面跳转），阻止它\t\tif ctx.Request.Type() == proto.NetworkResourceTypeDocument &amp;&amp; ctx.Request.URL().String() != url &#123;\t\t\tslog.Info(&quot;阻止页面跳转&quot;, &quot;ProxyService&quot;, ctx.Request.URL())\t\t\tctx.Response.Fail(proto.NetworkErrorReasonAborted)\t\t\treturn\t\t&#125;\t\tctx.MustLoadResponse()\t&#125;)\tgo router.Run()\t// 等待页面稳定\t// page.MustWaitStable()\t// 验证 navigator.webdriver\t_, evalErr := page.Eval(`navigator.webdriver`)\tif evalErr != nil &#123;\t\tslog.Error(&quot;验证 navigator.webdriver失败&quot;, &quot;ProxyService&quot;, evalErr)\t&#125;\t// 获取当前页面的所有 Cookie\tfor &#123;\t\tcookies := page.MustCookies()\t\tslog.Info(&quot;自动化拦截页面cookies&quot;, &quot;ProxyService&quot;, cookies)\t\tfor _, c := range cookies &#123;\t\t\tif c.Name == &quot;demo_cookies_name&quot; &amp;&amp; c.Value != &quot;&quot; &#123;    \t\tslog.Info(&quot;已拦截到demo_cookies_name&quot;, &quot;ProxyService&quot;, c.Value)\t\t\t\ttime.Sleep(1000 * time.Millisecond) // 等待1秒\t\t\t\tbrowser.MustClose() // 关闭浏览器\t\t\t\treturn // 结束当前函数\t\t\t&#125;\t\t&#125;\t\ttime.Sleep(100 * time.Millisecond) // 控制一下获取频率\t&#125;&#125;\n","slug":"2025-07-18-04","date":"2025-07-18T13:59:31.000Z","categories_index":"Go","tags_index":"Go","author_index":"Reverse"},{"id":"8a5374f6cc33ebcdaaad4a3c993161aa","title":"Hexo发布到GitHubPage报错404","content":"Number 1检查静态资源是否已经存在,访问地址:\nhttps://github.com/&lt;你的用户名&gt;/&lt;你的仓库&gt;/tree/&lt;静态文件分支&gt;\n如果你的工作流会将静态文件编译到指定分支的话,就有必要去看看是否编译出来了\nNumber 2进入你的 GitHub 仓库 &gt; Settings &gt; Pages &gt; Source &gt; 改为:Deploy from a branch\n并且下面的Branch分支需要改为你静态文件所在的分支,然后路径注意别错了,默认就/(root)就行\nNumber 3在 Hexo 的 _config.yml 配置文件中修改url参数,改为你实际的博客地址,比如我的\n1url: https://blog.hyhacct.com\n","slug":"2025-07-18-02","date":"2025-07-18T10:55:25.000Z","categories_index":"GitHub","tags_index":"GitHubPage","author_index":"Reverse"},{"id":"ac4f53f75d4e475cf1b29cd6d8ebee29","title":"在Github使用PAT方式跨仓库部署","content":"如果想直接用 Github Actions 的工作流自动化部署构建 Hexo 项目的话,需要编写 workflows 配置\n创建 Token首先去创建一个 Token\n\n访问 https://github.com/settings/tokens\n点击 “Fine-grained token”\n选择权限 repo （将这几个启用：contents、actions、deployments）\n有效期 随便多久都行,主要看你,我直接永久\n\n然后他会生成一个 Token,这个 Token 只显示一次,一定要先记下\n配置 Secrets接下来进入你的构建目标仓库,依次选择: Settings &gt; Secrets and variables &gt; Actions\n添加一个 secret,比如我这里变量名字叫 BLOG_TOKEN,然后值就是上面生成的 Token,填进去保存即可\n配置 workflows接着改改你的构建流程,把刚才创建的 BLOG_TOKEN 变量引用进去\n123456789101112131415161718192021222324252627282930313233343536name: Deploy Hexo to GitHub Pageson:  push:    branches:      - main # 或者是 master，根据你的默认分支修改jobs:  build-and-deploy:    runs-on: ubuntu-latest    steps:      - name: Checkout source code        uses: actions/checkout@v4      - name: Set up Node.js        uses: actions/setup-node@v4        with:          node-version: &quot;18&quot; # 根据你的项目需要修改 Node 版本          cache: &quot;npm&quot;      - name: Install dependencies        run: |          npm install -g hexo-cli          npm install      - name: Clean and generate Hexo site        run: |          hexo clean          hexo generate      - name: Deploy to GitHub Pages        uses: peaceiris/actions-gh-pages@v4        with:          github_token: $&#123;&#123; secrets.BLOG_TOKEN &#125;&#125;          publish_dir: ./public\n","slug":"2025-07-18-01","date":"2025-07-18T10:38:36.000Z","categories_index":"GitHub","tags_index":"GitHub","author_index":"Reverse"}]