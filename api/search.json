[{"id":"cb4e47217e236130c02e8a1c94b69087","title":"在Linux下创建System服务单元","content":"概述Systemd 是 Linux 系统的一种初始化系统（init），主要负责控制系统的启动和运行，并提供了一种基于服务的管理机制。它取代了传统的 init 系统，成为现代 Linux 发行版的标准。\n这里假设我需要为我的应用创建一个名字叫project-apps.service的服务单元。\n创建服务单元12345678910111213141516171819cat &gt;/etc/systemd/system/project-apps.service &lt;&lt;EOF[Unit]Description=project-apps ServiceAfter=network.target[Service]ExecStart=/usr/local/bin/project-appsRestart=alwaysUser=nobodyGroup=nogroupEnvironment=PATH=/usr/local/bin:/usr/bin:/bin[Install]WantedBy=multi-user.targetEOFsystemctl daemon-reloadsystemctl enable project-apps.servicesystemctl restart project-apps.service\n\n\ncat &gt;: 使用 cat 命令将后续内容写入文件。\n/etc/systemd/system/project-apps.service: 指定文件路径，systemd 服务单元文件通常存放在 &#x2F;etc&#x2F;systemd&#x2F;system&#x2F; 目录下。\n&lt;&lt;EOF ... EOF: 使用 heredoc 语法，将多行内容写入文件，直到遇到 EOF 标记。\n\n[Unit] 部分123[Unit]Description=project-apps ServiceAfter=network.target\n\n\nDescription: 服务描述，显示为 Dcim Service，用于标识服务的用途。\nAfter=network.target: 指定服务在 network.target（网络服务）启动后再启动，确保网络可用。\n\n[Service] 部分123456[Service]ExecStart=/usr/local/bin/project-appsRestart=alwaysUser=nobodyGroup=nogroupEnvironment=PATH=/usr/local/bin:/usr/bin:/bin\n\n\nExecStart: 指定服务启动时执行的命令 &#x2F;usr&#x2F;local&#x2F;bin&#x2F;project-apps。这意味着有一个可执行文件 project-apps 位于 &#x2F;usr&#x2F;local&#x2F;bin&#x2F;。\nRestart=always: 如果服务因任何原因停止（例如崩溃），systemd 将自动重启服务。\nUser=nobody: 服务以 nobody 用户身份运行，这是一个低权限用户，用于提高安全性。\nGroup=nogroup: 服务以 nogroup 组身份运行，同样是为了限制权限。\nEnvironment: 设置环境变量 PATH，确保服务可以找到 &#x2F;usr&#x2F;local&#x2F;bin、&#x2F;usr&#x2F;bin 和 &#x2F;bin 目录中的可执行文件。\n\n[Install] 部分12[Install]WantedBy=multi-user.target\n\n\nWantedBy=multi-user.target: 指定服务在 multi-user.target（多用户模式，相当于系统启动到命令行环境）时启用。这是典型的非图形化服务的目标。\n\n后续操作1systemctl daemon-reload\n\n\nsystemctl daemon-reload: 通知 systemd 重新加载配置文件。因为我们刚刚创建或修改了 dcim.service 文件，此命令确保 systemd 识别新的服务定义。\n需要 sudo 权限，因为修改 systemd 配置是系统级操作。\n\n12systemctl enable project-apps.servicesystemctl restart project-apps.service\n\n\nsystemctl enable project-apps.service: 启用服务，使其在系统启动时自动启动。\nsystemctl restart project-apps.service: 重新启动服务，确保配置生效。\n\n另外，如果需要查看服务状态，可以使用以下命令：\n1systemctl status project-apps.service\n\n希望查看服务日志，可以使用以下命令：\n1journalctl -u project-apps.service\n","slug":"2025-07-18-09","date":"2025-07-18T14:16:37.000Z","categories_index":"运维","tags_index":"服务单元 Linux","author_index":"Reverse"},{"id":"412695f5eb189a644d181b95b6e4062a","title":"在Linux下创建Supervisord服务单元","content":"概述Supervisord 是一个轻量级的进程管理工具。它允许创建和管理多个进程，并提供一些高级功能，如进程监控、自动重启、日志管理等。\n他和 Systemd 一样，都是用于管理进程的工具。\n安装1apt install supervisor\n\n安装完成后有个配置文件: supervisord.conf 如果找不到的话用 find 寻找一下就行.\n然后需要启动 supervisord 服务:\n1supervisord -c /etc/supervisor/supervisord.conf\n\n\n\n\n\n\n\n\n\n\n注意下,这里的配置文件是你实际的配置文件所在路径,如果你移动过这个 conf 文件的位置,请使用实际的路径.\n进行配置和上一篇文章一样继续假设我们的应用叫 project-apps 并且需要创建一个服务单元.\n给supervisord 添加配置:\n1234567891011121314151617[supervisord]nodaemon=truelogfile=/dev/nulllogfile_maxbytes=0pidfile=/tmp/supervisord.pid[program:project-apps]command=/usr/local/bin/project-appsuser=nobodyenvironment=PATH=&quot;/usr/local/bin:/usr/bin:/bin&quot;autostart=trueautorestart=truestartsecs=10startretries=3redirect_stderr=truestdout_logfile=/dev/stdoutstderr_logfile=/dev/stderr\n\n逐项解释：\n[supervisord] 部分：\n\nnodaemon=true：以非守护进程模式运行（容器需要前台进程）。\nlogfile=/dev/null：禁用 supervisord 自身的日志文件（容器日志通过 stdout&#x2F;stderr 收集）。\nlogfile_maxbytes=0：防止日志文件增长。\npidfile=/tmp/supervisord.pid：指定 PID 文件路径。\n\n[program:project-apps] 部分：\n\ncommand=/usr/local/bin/project-apps：运行的命令，等价于 systemd 的 ExecStart。\nuser=nobody：以 nobody 用户运行，等价于 systemd 的 User&#x3D;nobody。\nenvironment=PATH=...：设置环境变量，等价于 systemd 的 Environment。\nautostart=true：supervisord 启动时自动启动 project-apps\nautorestart=true：进程退出时自动重启，等价于 systemd 的 Restart&#x3D;always。\nstartsecs=10：进程运行 10 秒后认为启动成功（避免频繁重启）。\nstartretries=3：启动失败时重试 3 次。\nredirect_stderr=true：将 stderr 重定向到 stdout。\nstdout_logfile=/dev/stdout：将 stdout 输出到容器日志。\nstderr_logfile=/dev/stderr：将 stderr 输出到容器日志。\n\n启动1supervisord -c /etc/supervisor/supervisord.conf\n\n查看状态1supervisorctl status\n\n停止1supervisorctl stop project-apps\n\n重启1supervisorctl restart project-apps\n\n支持的各个参数\n\n\n参数名\n描述\n类型\n默认值\n示例值\n与 systemd 的对应\n\n\n\ncommand\n指定要运行的命令或可执行文件路径\n字符串\n无（必填）\nproject-apps\nExecStart\n\n\nuser\n指定运行进程的用户\n字符串\n无（以 supervisord 的用户运行）\nnobody\nUser\n\n\nenvironment\n设置进程的环境变量，格式为 KEY&#x3D;”value”,KEY2&#x3D;”value2”\n字符串\n无\nPATH=&quot;/usr/local/bin:/usr/bin:/bin&quot;\nEnvironment\n\n\ndirectory\n运行命令前切换的工作目录\n字符串\n无（当前目录）\n/app\nWorkingDirectory\n\n\nautostart\n是否在 supervisord 启动时自动启动进程\n布尔值\ntrue\ntrue\nWantedBy（间接对应）\n\n\nautorestart\n进程退出时是否自动重启（true&#x2F;false&#x2F;unexpected）\n字符串\nfalse\ntrue\nRestart（always 对应 true）\n\n\nstartsecs\n进程运行多少秒后认为启动成功（用于重启判断）\n整数\n1\n10\n无直接对应（类似 RestartSec）\n\n\nstartretries\n启动失败时的最大重试次数\n整数\n3\n3\n无直接对应\n\n\nexitcodes\n视为正常退出的退出码（仅当 autorestart&#x3D;unexpected 时生效）\n逗号分隔的整数\n0\n0,2\n无直接对应\n\n\nstopwaitsecs\n停止进程时等待的秒数（超时后发送 SIGKILL）\n整数\n10\n10\nTimeoutStopSec\n\n\nstopasgroup\n是否向整个进程组发送停止信号\n布尔值\nfalse\ntrue\n无直接对应（类似 KillMode&#x3D;process-group）\n\n\nkillasgroup\n是否向整个进程组发送终止信号（SIGKILL）\n布尔值\nfalse\ntrue\n无直接对应\n\n\nstopsignal\n用于停止进程的信号\n字符串\nTERM\nINT\nKillSignal\n\n\npriority\n进程启动的优先级（数字越小优先级越高）\n整数\n999\n100\n无直接对应（类似 Nice 或启动顺序）\n\n\nnumprocs\n启动的进程实例数（多实例运行）\n整数\n1\n2\n无直接对应\n\n\nnumprocs_start\n多实例进程的起始编号（与 numprocs 配合）\n整数\n0\n1\n无直接对应\n\n\nprocess_name\n进程名称模板（用于多实例，含 % 占位符）\n字符串\n%(program_name)s\n%(program_name)s_%(process_num)02d\n无直接对应\n\n\nredirect_stderr\n是否将 stderr 重定向到 stdout\n布尔值\nfalse\ntrue\n无直接对应（日志处理相关）\n\n\nstdout_logfile\nstdout 日志输出文件路径（支持 &#x2F;dev&#x2F;stdout）\n字符串\nAUTO（自动生成日志文件）\n/dev/stdout\n无直接对应（systemd 使用 journalctl）\n\n\nstdout_logfile_maxbytes\nstdout 日志文件的最大大小\n字符串\n50MB\n10MB\n无直接对应\n\n\nstdout_logfile_backups\nstdout 日志文件的备份数量\n整数\n10\n5\n无直接对应\n\n\nstderr_logfile\nstderr 日志输出文件路径\n字符串\nAUTO\n/dev/stderr\n无直接对应\n\n\nstderr_logfile_maxbytes\nstderr 日志文件的最大大小\n字符串\n50MB\n10MB\n无直接对应\n\n\nstderr_logfile_backups\nstderr 日志文件的备份数量\n整数\n10\n5\n无直接对应\n\n\nstdout_capture_maxbytes\nstdout 捕获缓冲区大小（用于事件监听）\n字符串\n0\n1MB\n无直接对应\n\n\nstdout_events_enabled\n是否启用 stdout 事件（用于事件监听）\n布尔值\nfalse\ntrue\n无直接对应\n\n\nstderr_events_enabled\n是否启用 stderr 事件\n布尔值\nfalse\ntrue\n无直接对应\n\n\n","slug":"2025-07-18-08","date":"2025-07-18T14:16:37.000Z","categories_index":"运维","tags_index":"服务单元 Linux","author_index":"Reverse"},{"id":"5cd89c20fd6a2aad9144cf965a99cbdc","title":"利用zabbix api计算流量月95值","content":"直接提供脚本虽然这个脚本是让 AI 帮忙写的,但经过实际验证,是有效的,并且我一直在使用\n\n\n\n\n\n\n\n\n\n注意这的 1,2,3 步骤中的一些参数需要自己配置,比如时间范围,单位换算,文件路径等.\n根据你实际情况改改,另外就是一些必备软件包得装一下,比如jq bc curl什么的.\n最重要的是ITEM_ID这个变量,你需要从 zabbix 中找到你想计算 95 的流量图,然后把他的 itemid 拿出来.\n12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394#!/usr/bin/env bash# 1. Zabbix API 参数配置ZABBIX_URL=&quot;https://xxxxxxx/api_jsonrpc.php&quot; # 你的 zabbix API 地址ITEM_ID=&quot; 123456&quot; # 你的 item id,这个是流量图的 itemid,可以自己找一下AUTH_TOKEN=&quot;xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx&quot; # 你的 auth token# 2. 时间范围,假设（2025-04-01 ~ 2025-04-30）TIME_FROM=1743436800 # 2025-04-01 00:00:00 转换到对应的秒级时间戳TIME_TILL=1746028799 # 2025-04-30 23:59:59 转换到对应的秒级时间戳# 3. 单位换算：字节 =&gt; MBBYTES_TO_MB=1048576JSON_PATH=&quot;/tmp/zabbix.json&quot; # zbx 请求数据CSV_PATH=&quot;/tmp/zabbix_full_data.csv&quot; # 全量数据(每 5 分钟一个点的 95 值)ROW_PATH=&quot;/tmp/zabbix_row_data.csv&quot; # 每分钟数据# 4. 获取历史数据（只下载一次）if [ ! -f &quot;$JSON_PATH&quot; ]; then  echo &quot;拉取 Zabbix 数据中...&quot;  RESPONSE=$(curl -s &quot;$ZABBIX_URL&quot; \\    -H &quot;Content-Type: application/json&quot; \\    --data-raw &quot;&#123;    \\&quot;jsonrpc\\&quot;: \\&quot;2.0\\&quot;,    \\&quot;id\\&quot;: 1,    \\&quot;method\\&quot;: \\&quot;history.get\\&quot;,    \\&quot;params\\&quot;: &#123;      \\&quot;output\\&quot;: \\&quot;extend\\&quot;,      \\&quot;itemids\\&quot;: \\&quot;$ITEM_ID\\&quot;,      \\&quot;history\\&quot;: 3,      \\&quot;time_from\\&quot;: $TIME_FROM,      \\&quot;time_till\\&quot;: $TIME_TILL,      \\&quot;sortfield\\&quot;: [\\&quot;clock\\&quot;, \\&quot;itemid\\&quot;],      \\&quot;sortorder\\&quot;: \\&quot;ASC\\&quot;    &#125;,    \\&quot;auth\\&quot;: \\&quot;$AUTH_TOKEN\\&quot;  &#125;&quot;)  echo &quot;$RESPONSE&quot; &gt;&quot;$JSON_PATH&quot;else  RESPONSE=$(awk &#x27;NF&#x27; &quot;$JSON_PATH&quot;)fi# 5. 提取时间和流量，转换为 MB，并写入 CSV 文件echo &quot;Timestamp,Datetime,Value(MB)&quot; &gt;&quot;$CSV_PATH&quot;# 暂存 5 分钟分组后的最大值declare -A GROUPED_MAX# 从 JSON 中提取数据并分组while IFS= read -r line; do  CLOCK=$(echo &quot;$line&quot; | jq -r &#x27;.clock&#x27;)  VALUE=$(echo &quot;$line&quot; | jq -r &#x27;.value&#x27;)  VALUE_MB=$(awk -v val=&quot;$VALUE&quot; -v factor=&quot;$BYTES_TO_MB&quot; &#x27;BEGIN &#123;printf &quot;%.2f&quot;, val / factor&#125;&#x27;)  # 向下取整到 5 分钟（300 秒）粒度  GROUP_TS=$((CLOCK / 300 * 300))  # 如果该组未存在，或当前值更大，更新最大值  if [[ -z &quot;$&#123;GROUPED_MAX[$GROUP_TS]&#125;&quot; ]] || (($(echo &quot;$VALUE_MB &gt; $&#123;GROUPED_MAX[$GROUP_TS]&#125;&quot; | bc -l))); then    GROUPED_MAX[$GROUP_TS]=$VALUE_MB  fi  # 写出每分钟的数据,带可读时间  DATETIME=$(date -d &quot;@$CLOCK&quot; &quot;+%Y-%m-%d %H:%M:%S&quot;)  echo &quot;$DATETIME,$VALUE_MB&quot; &gt;&gt;&quot;$ROW_PATH&quot;done &lt; &lt;(echo &quot;$RESPONSE&quot; | jq -c &#x27;.result | sort_by(.clock)[]&#x27;)# 提取排序后的 5 分钟粒度时间点和值，写入 CSV，并保存值用于 P95VALUES_MB=()for ts in $(printf &quot;%s\\n&quot; &quot;$&#123;!GROUPED_MAX[@]&#125;&quot; | sort -n); do  val=&quot;$&#123;GROUPED_MAX[$ts]&#125;&quot;  datetime=$(date -d &quot;@$ts&quot; &quot;+%Y-%m-%d %H:%M:%S&quot;)  echo &quot;$ts,$datetime,$val&quot; &gt;&gt;&quot;$CSV_PATH&quot;  VALUES_MB+=(&quot;$val&quot;)done# 6. 统计与 P95 计算TOTAL=$&#123;#VALUES_MB[@]&#125;if [[ $TOTAL -lt 1 ]]; then  echo &quot;未获取到有效数据，退出。&quot;  exit 1fiSORTED=($(printf &quot;%s\\n&quot; &quot;$&#123;VALUES_MB[@]&#125;&quot; | sort -n))PERCENTILE_INDEX=$(echo &quot;$TOTAL * 0.95&quot; | bc | awk &#x27;&#123;printf(&quot;%d&quot;, ($1==int($1))?$1:$1+1)&#125;&#x27;)P95_VALUE=$&#123;SORTED[$((PERCENTILE_INDEX - 1))]&#125;# 7. 输出汇总echo &quot;✅ 数据点总数: $TOTAL&quot;echo &quot;📈 95 百分位位置: $PERCENTILE_INDEX&quot;echo &quot;📊 整体 95 值: $P95_VALUE MB&quot;echo &quot;📁 CSV 文件已生成: $CSV_PATH&quot;\n\n最终结果大概长这样:\n1234567✅ 数据点总数: 3589📈 95 百分位位置: 3410📊 整体 95 值: 1955.15 MB📁 CSV 文件已生成: /tmp/zabbix_full_data.csv\n","slug":"2025-07-18-07","date":"2025-07-18T14:12:49.000Z","categories_index":"运维","tags_index":"zabbix 月95","author_index":"Reverse"},{"id":"c59c56761bc7b0b0394e25c388e5d7f6","title":"利用nftables做端口流量统计","content":"概述通过nftables规则对特定端口范围做计数流量统计,可以借此计算瞬时流量.\n写规则假设这里我统计的是11000-19000端口范围的流量,入站和出站都统计,然后用计数器来计算流量.\n大概流程就是创一个名字叫portstats的表,然后创两个链,一个叫input_chain,一个叫output_chain,\n然后创两个计数器,一个叫input_tcp_range,一个叫output_tcp_range,然后创两个规则,一个叫input_tcp_range,一个叫output_tcp_range.\n12345678910111213141516171819202122232425262728293031# 创建表和链nft add table inet portstatsnft add chain inet portstats input_chain &#123; type filter hook input priority 0\\; &#125;nft add chain inet portstats output_chain &#123; type filter hook output priority 0\\; &#125;# 创建表nft add table inet portstats# 创建 input 链（接收进入本机的数据）nft add chain inet portstats input_chain &#123; type filter hook input priority 0\\; &#125;# 创建 output 链（从本机发出的数据）nft add chain inet portstats output_chain &#123; type filter hook output priority 0\\; &#125;# 创建计数器 TCPnft add counter inet portstats input_tcp_rangenft add counter inet portstats output_tcp_range# 创建计数器 UDPnft add counter inet portstats input_udp_rangenft add counter inet portstats output_udp_range# 入站 TCPnft add rule inet portstats input_chain tcp dport 11000-19000 counter name input_tcp_range# 入站 UDPnft add rule inet portstats input_chain udp dport 11000-19000 counter name input_udp_range# 出站 TCPnft add rule inet portstats output_chain tcp sport 11000-19000 counter name output_tcp_range# 出站 UDPnft add rule inet portstats output_chain udp sport 11000-19000 counter name output_udp_range\n\n创建完成后,可以查看这个表,能直接看到他的流量统计.\n在输出中,能看到counter的流量统计,packets是包的数量,bytes是字节数.\n\ninput_tcp_range 入站 TCP 流量统计\noutput_tcp_range 出站 TCP 流量统计\ninput_udp_range 入站 UDP 流量统计\noutput_udp_range 出站 UDP 流量统计\n\n\n\n\n\n\n\n\n\n\n当然,你可以直接通过他的 bytes 来计算计数流量,包括瞬时流量你也能记录到.\n1nft list table inet portstats\n\n1234567891011121314151617181920212223242526272829303132333435root@localhost:~# nft list table inet portstatstable inet portstats &#123;        counter input_tcp_range &#123;                packets 3646743 bytes 234844099        &#125;        counter output_tcp_range &#123;                packets 2718337 bytes 7699060368        &#125;        counter input_udp_range &#123;                packets 83 bytes 12353        &#125;        counter output_udp_range &#123;                packets 96 bytes 7375        &#125;        chain input_chain &#123;                type filter hook input priority filter; policy accept;                tcp dport 11000-19000 counter name &quot;input_tcp_range&quot;                udp dport 11000-19000 counter name &quot;input_udp_range&quot;                tcp dport 11000-19000 counter name &quot;input_tcp_range&quot;                udp dport 11000-19000 counter name &quot;input_udp_range&quot;        &#125;        chain output_chain &#123;                type filter hook output priority filter; policy accept;                tcp sport 11000-19000 counter name &quot;output_tcp_range&quot;                udp sport 11000-19000 counter name &quot;output_udp_range&quot;                tcp sport 11000-19000 counter name &quot;output_tcp_range&quot;                udp sport 11000-19000 counter name &quot;output_udp_range&quot;        &#125;&#125;root@localhost:~#\n\n流量计算比如上面的output_tcp_range当前流量在7699060368字节,如果要转换到 Mb 单位,你应该:\n1echo &#x27;scale=2; 7699060368 / 1048576&#x27; | bc\n\n单位是 Mb,这样计算出来的结果仅仅只是计数器记录的流量,并不是瞬时流量.\n17342.39\n\n计算瞬时流量原理也很简单,先获取当前计数器记录的流量,然后 sleep10 秒后,再获取一次计数器记录的流量,然后计算两次的差值.\n123nft list table inet portstatssleep 10 # 等待 10 秒再取一次nft list table inet portstats\n\n比如我这里两次执行结果的input_tcp_range.\n\n第一次 234844099\n第二次 4346338221\n那么瞬时流量计算方式直接参考以下脚本\n\n\n\n\n\n\n\n\n\n\n第二次的结果减去第一次的结果,并且除以 10 的延迟秒,得到瞬时流量(如果要到 Mb 单位则再除以 1048576).\n如果你的延迟设置的不是 10 秒,而是 60 秒,那你就得除以 60.\n1echo &#x27;scale=2; (4346338221 - 234844099) / 1048576 / 10&#x27; | bc # 单位是 Mb/s\n\n1392.10\n\n删除规则如果后续你不想要这个表或者这些规则了,可以直接删除这张表,他会将这个表下的规则,链,计数器一并清理.\n1nft delete table inet portstats\n","slug":"2025-07-18-06","date":"2025-07-18T14:10:07.000Z","categories_index":"运维","tags_index":"nftables","author_index":"Reverse"},{"id":"5861fe1ef331a2f0173b8f2c74ba7f6a","title":"为服务器启用超线程模式","content":"查看是否启用超线程如果 Thread(s) per core: 2，说明超线程已启用（每个物理核心有 2 个逻辑线程）。\n如果 Thread(s) per core: 1，说明超线程未启用。\n1lscpu | grep &quot;Thread(s) per core&quot;\n\n启用所有核心大概这样,写入 1 表示启用此核心,确保核心全部启用\n1234for CPU in /sys/devices/system/cpu/cpu[0-9]*; do  sudo bash -c &quot;echo 1 &gt; $CPU/online&quot; 2&gt;/dev/nulldonelscpu | grep &quot;Thread(s) per core&quot;\n\n启用超线程这里以 PowerEdge R730 机型为例,重启按 F2 进入 BIOS.\n然后按照下面的图片找到对应的选项并且将其启用即可\n\n进入 System BIOS 选项\n选择 Precessor Settings 选项(处理器设置)\n将 Logical Processor 设置为 Enable(启用即可)\n\n\n\n\n\n\n\n\n\n\nLogical Processor 的名字其实不一定,有时也叫 Hyper-Threading 或 Logical Processor Enable 看是什么机型\n\n\n\n验证结果保存 BIOS 配置并且退出,然后重启进入系统,再次尝试查看\n输出结果中的Thread(s) per core为 2 表示就启用了超线程\n1lscpu | grep &quot;Thread(s) per core&quot;\n\n或者\n1lscpu\n","slug":"2025-07-18-05","date":"2025-07-18T14:06:43.000Z","categories_index":"运维","tags_index":"超线程","author_index":"Reverse"},{"id":"b72299e78af8a95e50e0ce74a5a78e6d","title":"NaiveUI的Table表分页配置","content":"因为 NaiveUI 的 DataTable 数据表格组件支持 pagination 参数,所以我一直固定使用这个模板来作为分配配置,而不需要后端来分页\n\n\n\n\n\n\nTIP\n参考代码,在代码中,你无需关注他是怎么实现的,只需要定义好pagination对象,并且配置到数据表格组件中的 pagination 参数即可\n\n1234567891011121314151617181920212223242526272829303132333435&lt;template&gt;  &lt;n-data-table :pagination=&quot;pagination&quot; /&gt;&lt;/template&gt;&lt;script setup&gt;const pagination = &#123;  prefix(&#123; itemCount &#125;) &#123;    return `总计 $&#123;itemCount&#125; 条数据`;  &#125;,  pageSizes: [    &#123;      label: &quot;默认10条&quot;,      value: 10,    &#125;,    &#123;      label: &quot;全部显示&quot;,      value: 9999,    &#125;,    &#123;      label: &quot;20 每页&quot;,      value: 20,    &#125;,    &#123;      label: &quot;30 每页&quot;,      value: 30,    &#125;,    &#123;      label: &quot;40 每页&quot;,      value: 40,    &#125;,  ],  showSizePicker: true,  displayOrder: [&quot;quick-jumper&quot;, &quot;pages&quot;, &quot;size-picker&quot;],&#125;;&lt;/script&gt;\n","slug":"2025-07-18-03","date":"2025-07-18T13:59:31.000Z","categories_index":"Vue.js","tags_index":"Vue.js NaiveUI","author_index":"Reverse"},{"id":"1c2170fb6fef60f29c3c2770dcf97c19","title":"使用Go从Chroom中获取页面Cookies","content":"概述浅浅的玩一下github.com/go-rod/rod这个库.\n通过这个支持库,可以很方便的打开一个浏览器并且让他访问一个 url,在他访问 url 时你还可以监听这个 url 的 cookies.\n开始实操为了防止被检测到自动化，我这里是注入了 js 屏蔽了检测。\n\n首先使用browser.MustPage(&quot;&quot;)打开了一个空的标签页。\n注入 JS 脚本修改navigator.webdriver为false。\n注入修改完成后再打开真实的目标 URL，这样目标网站就没法通过这个值去检测我是不是自动化程序了。\n同时滑块成功后页面会自动跳转到其他地方，所以我做了一个拦截，如果不需要的话可以直接删除。\n\n\n\n\n\n\n\n\n\n\n可能要注意下，不一定所有的站点都是通过webdriver来检测自动化程序的，但是我这里只提供这个方式，至于其他的需要按照实际场景来看。\n并且我这里 go 程序只是为了获取滑块后的 cookies，如果想获取请求头或者其他东西的话，可能得自己再研究下。\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778package mainimport (\t&quot;context&quot;\t&quot;log/slog&quot;\t&quot;time&quot;\t&quot;github.com/go-rod/rod&quot;\t&quot;github.com/go-rod/rod/lib/launcher&quot;\t&quot;github.com/go-rod/rod/lib/proto&quot;)func main() &#123;  url := &quot;https://qq.com&quot;\tu := launcher.New().\t\tHeadless(false). // 显示窗口\t\t// 设置窗口尺寸（可选）\t\tSet(&quot;window-size&quot;, &quot;1200,800&quot;).\t\tSet(&quot;disable-blink-features&quot;, &quot;AutomationControlled&quot;).\t\tMustLaunch()\tbrowser := rod.New().ControlURL(u).MustConnect()\t// 打开页面\tpage := browser.MustPage(&quot;&quot;)\t// 在页面加载前注入 JavaScript，修改 navigator.webdriver\t_, err := page.EvalOnNewDocument(`\t\tObject.defineProperty(navigator, &#x27;webdriver&#x27;, &#123;\t\t\tget: () =&gt; false\t\t&#125;);\t`)\tif err != nil &#123;\t\tslog.Error(&quot;在页面加载前注入 JavaScript，修改 navigator.webdriver失败&quot;, &quot;ProxyService&quot;, err)\t&#125;\t// 访问目标页面\tpage.MustNavigate(url).MustWaitLoad()\t// 拦截导航请求，禁止跳转\trouter := page.HijackRequests()\trouter.MustAdd(&quot;*&quot;, func(ctx *rod.Hijack) &#123;\t\t// 如果请求是导航（即页面跳转），阻止它\t\tif ctx.Request.Type() == proto.NetworkResourceTypeDocument &amp;&amp; ctx.Request.URL().String() != url &#123;\t\t\tslog.Info(&quot;阻止页面跳转&quot;, &quot;ProxyService&quot;, ctx.Request.URL())\t\t\tctx.Response.Fail(proto.NetworkErrorReasonAborted)\t\t\treturn\t\t&#125;\t\tctx.MustLoadResponse()\t&#125;)\tgo router.Run()\t// 等待页面稳定\t// page.MustWaitStable()\t// 验证 navigator.webdriver\t_, evalErr := page.Eval(`navigator.webdriver`)\tif evalErr != nil &#123;\t\tslog.Error(&quot;验证 navigator.webdriver失败&quot;, &quot;ProxyService&quot;, evalErr)\t&#125;\t// 获取当前页面的所有 Cookie\tfor &#123;\t\tcookies := page.MustCookies()\t\tslog.Info(&quot;自动化拦截页面cookies&quot;, &quot;ProxyService&quot;, cookies)\t\tfor _, c := range cookies &#123;\t\t\tif c.Name == &quot;demo_cookies_name&quot; &amp;&amp; c.Value != &quot;&quot; &#123;    \t\tslog.Info(&quot;已拦截到demo_cookies_name&quot;, &quot;ProxyService&quot;, c.Value)\t\t\t\ttime.Sleep(1000 * time.Millisecond) // 等待1秒\t\t\t\tbrowser.MustClose() // 关闭浏览器\t\t\t\treturn // 结束当前函数\t\t\t&#125;\t\t&#125;\t\ttime.Sleep(100 * time.Millisecond) // 控制一下获取频率\t&#125;&#125;\n","slug":"2025-07-18-04","date":"2025-07-18T13:59:31.000Z","categories_index":"Go","tags_index":"Go","author_index":"Reverse"},{"id":"8a5374f6cc33ebcdaaad4a3c993161aa","title":"Hexo发布到GitHubPage报错404","content":"Number 1检查静态资源是否已经存在,访问地址:\nhttps://github.com/&lt;你的用户名&gt;/&lt;你的仓库&gt;/tree/&lt;静态文件分支&gt;\n如果你的工作流会将静态文件编译到指定分支的话,就有必要去看看是否编译出来了\nNumber 2进入你的 GitHub 仓库 &gt; Settings &gt; Pages &gt; Source &gt; 改为:Deploy from a branch\n并且下面的Branch分支需要改为你静态文件所在的分支,然后路径注意别错了,默认就/(root)就行\nNumber 3在 Hexo 的 _config.yml 配置文件中修改url参数,改为你实际的博客地址,比如我的\n1url: https://blog.hyhacct.com\n","slug":"2025-07-18-02","date":"2025-07-18T10:55:25.000Z","categories_index":"GitHub","tags_index":"GitHubPage","author_index":"Reverse"},{"id":"ac4f53f75d4e475cf1b29cd6d8ebee29","title":"在Github使用PAT方式跨仓库部署","content":"如果想直接用 Github Actions 的工作流自动化部署构建 Hexo 项目的话,需要编写 workflows 配置\n创建 Token首先去创建一个 Token\n\n访问 https://github.com/settings/tokens\n点击 “Fine-grained token”\n选择权限 repo （将这几个启用：contents、actions、deployments）\n有效期 随便多久都行,主要看你,我直接永久\n\n然后他会生成一个 Token,这个 Token 只显示一次,一定要先记下\n配置 Secrets接下来进入你的构建目标仓库,依次选择: Settings &gt; Secrets and variables &gt; Actions\n添加一个 secret,比如我这里变量名字叫 BLOG_TOKEN,然后值就是上面生成的 Token,填进去保存即可\n配置 workflows接着改改你的构建流程,把刚才创建的 BLOG_TOKEN 变量引用进去\n123456789101112131415161718192021222324252627282930313233343536name: Deploy Hexo to GitHub Pageson:  push:    branches:      - main # 或者是 master，根据你的默认分支修改jobs:  build-and-deploy:    runs-on: ubuntu-latest    steps:      - name: Checkout source code        uses: actions/checkout@v4      - name: Set up Node.js        uses: actions/setup-node@v4        with:          node-version: &quot;18&quot; # 根据你的项目需要修改 Node 版本          cache: &quot;npm&quot;      - name: Install dependencies        run: |          npm install -g hexo-cli          npm install      - name: Clean and generate Hexo site        run: |          hexo clean          hexo generate      - name: Deploy to GitHub Pages        uses: peaceiris/actions-gh-pages@v4        with:          github_token: $&#123;&#123; secrets.BLOG_TOKEN &#125;&#125;          publish_dir: ./public\n","slug":"2025-07-18-01","date":"2025-07-18T10:38:36.000Z","categories_index":"GitHub","tags_index":"GitHub","author_index":"Reverse"},{"id":"a6b82868af4785482b869dc5d958966b","title":"Article Title","content":"这是一个博客\n\n\n\n\n\n\nTIP\nhello\n\n\n\n\n\n\n\n\n[hello]\n文本内容\n\n","slug":"hello-world","date":"2020-08-15T18:49:36.000Z","categories_index":"Cate","tags_index":"Tag","author_index":"Reverse"}]